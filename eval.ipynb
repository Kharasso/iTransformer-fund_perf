{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torcheval.metrics import R2Score\n",
    "from utils.metrics import metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_dir = \"./long_short_pred_results\"\n",
    "fnames = os.listdir(test_result_dir)\n",
    "fnames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_r2(preds, trues):\n",
    "    metrics = R2Score()\n",
    "    input = torch.tensor(preds.flatten())\n",
    "    target = torch.tensor(trues.flatten())  \n",
    "    metrics.update(input, target)\n",
    "    \n",
    "    return metrics.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_rows = []\n",
    "cols = ['yearmonth', 'm1', 'm2', 'm3', 'all']\n",
    "\n",
    "for fn in fnames:\n",
    "    res_df = pd.read_csv(os.path.join(test_result_dir, fn))\n",
    "    months = sorted(res_df['yearmonth'].unique())\n",
    "\n",
    "    r2_row = [months[0]]\n",
    "\n",
    "    for month in months:\n",
    "        preds = res_df.loc[res_df['yearmonth'] == month, 'mean'].to_numpy()\n",
    "        trues = res_df.loc[res_df['yearmonth'] == month, 'exret'].to_numpy()\n",
    "        \n",
    "        r2_row.append(calc_r2(preds, trues))\n",
    "    \n",
    "    preds = res_df['mean'].to_numpy()\n",
    "    trues = res_df['exret'].to_numpy()\n",
    "    r2_row.append(calc_r2(preds, trues))\n",
    "\n",
    "    r2_rows.append(r2_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = pd.DataFrame(r2_rows, columns=cols)\n",
    "all_res.sort_values(by=['all'], ascending=False).to_csv('r2_monthly_res.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv(\"./long_short_pred_results/results_2014-11-15_2015-01-15.csv\")\n",
    "preds = res_df['mean'].to_numpy()\n",
    "trues = res_df['exret'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2014-11', '2014-12', '2015-01']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(res_df['yearmonth'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.3200e-02, -1.4000e-02, -1.0900e-02, -1.4959e-03,  8.7218e-03,\n",
       "        -8.0100e-02,  1.3120e-01,  1.4914e-02, -2.2079e-02, -3.2838e-02,\n",
       "        -4.0000e-04,  5.6600e-02, -2.0000e-03,  4.2194e-04, -1.3700e-02,\n",
       "        -4.5000e-03, -5.6598e-02, -6.0649e-02, -5.1700e-02, -1.9200e-02,\n",
       "        -1.2600e-02, -1.5000e-02, -4.8588e-04, -1.1248e-02, -7.6500e-04,\n",
       "        -4.6300e-02, -6.1000e-02,  1.6300e-02, -2.1800e-02,  2.4530e-02,\n",
       "        -6.0000e-02, -1.7700e-02, -5.2000e-03, -2.4000e-02,  2.0400e-02,\n",
       "         3.5030e-02, -5.6172e-03, -1.3000e-02,  1.1700e-02,  6.6000e-03,\n",
       "         5.0072e-02,  7.0000e-03,  7.0000e-03, -2.8981e-03, -2.2100e-02,\n",
       "        -5.8800e-02, -5.9200e-02,  7.3000e-03, -3.5800e-02, -3.5800e-02,\n",
       "        -3.7500e-02, -3.7500e-02,  3.1200e-02, -3.5066e-02,  2.4000e-03,\n",
       "        -3.5600e-02,  7.0000e-03, -1.6620e-02,  4.1413e-02, -1.5800e-02,\n",
       "        -7.1000e-03, -4.9600e-02, -1.0900e-02,  5.9000e-03, -4.3675e-02,\n",
       "         3.6312e-02,  1.8800e-02,  2.4000e-03, -1.0100e-02, -4.9600e-02,\n",
       "         8.1669e-03,  4.7530e-02, -9.3000e-03, -6.4889e-02,  3.9600e-04,\n",
       "        -1.8110e-02,  2.2000e-03,  7.0000e-03, -1.3900e-02,  6.7000e-03,\n",
       "        -2.6100e-02, -4.3030e-03, -2.4978e-03,  6.6200e-02, -4.6300e-02,\n",
       "         4.1671e-03, -3.5708e-03,  1.4000e-03,  2.1642e-03,  1.4000e-04,\n",
       "        -2.7000e-05, -4.9000e-02,  3.7800e-02, -1.7605e-03, -2.5100e-02,\n",
       "        -4.8000e-03,  6.9441e-02, -2.5734e-02, -8.9000e-03, -8.6000e-03,\n",
       "         1.3120e-01,  1.5000e-03,  2.2665e-02,  6.8500e-02, -1.0000e-03,\n",
       "         2.4000e-03,  1.8610e-02, -2.6900e-02, -3.5200e-02, -3.4400e-02,\n",
       "        -1.0490e-02,  1.2000e-02, -2.5400e-02, -1.6100e-02, -6.7000e-03,\n",
       "        -9.1000e-03,  2.6600e-02,  7.0000e-04, -1.1644e-02, -1.3000e-03,\n",
       "        -1.5500e-02,  1.3110e-01, -5.0300e-02,  2.8700e-02, -2.2700e-02,\n",
       "        -2.8309e-03,  6.4977e-03,  2.5316e-03,  1.1500e-02, -5.7000e-03,\n",
       "         1.2100e-02,  3.8288e-02, -3.5100e-02, -2.2311e-02, -9.4000e-02,\n",
       "        -4.6918e-03,  2.3100e-02,  6.3400e-02,  6.3500e-02, -3.5600e-02,\n",
       "        -3.5600e-02, -1.0300e-02, -1.0600e-02,  2.1480e-02,  2.2008e-02,\n",
       "         1.1100e-02,  8.8452e-03, -3.0600e-03, -5.3000e-03, -1.5800e-02,\n",
       "        -1.7000e-02,  3.7600e-02,  1.9708e-02,  1.3120e-01,  7.2957e-03,\n",
       "         5.0000e-04, -3.4800e-02,  2.8500e-03, -4.9000e-03, -4.9000e-03,\n",
       "         1.1600e-02,  2.0000e-03, -1.4971e-02,  6.3000e-03, -1.9500e-02,\n",
       "         2.6000e-02,  7.0000e-04,  3.4000e-05, -2.5100e-02, -5.1974e-03,\n",
       "        -2.5000e-03,  6.2000e-03,  6.2000e-03,  2.6290e-03, -2.9215e-03,\n",
       "        -2.0600e-02, -7.3900e-02, -3.0000e-03,  2.8700e-02,  0.0000e+00,\n",
       "         4.7148e-02,  3.8722e-02, -3.8000e-03, -1.5100e-02,  1.4300e-02,\n",
       "         3.8358e-03,  3.0957e-02,  3.9780e-02,  2.0000e-04, -2.7800e-02,\n",
       "        -2.8900e-02,  2.8898e-02,  2.9718e-02,  1.1700e-02, -1.3999e-02,\n",
       "        -7.4699e-03,  1.3120e-01,  5.7100e-02, -1.9639e-03, -3.6000e-03,\n",
       "        -3.3700e-02,  1.6200e-02, -1.7400e-02,  3.6000e-03, -3.4200e-02,\n",
       "         1.5000e-03,  1.4000e-03,  5.6000e-03, -1.7000e-03, -5.8000e-03,\n",
       "        -5.1730e-02, -5.5000e-03,  1.6206e-02, -2.6600e-02, -8.0000e-03,\n",
       "        -1.6900e-02,  5.7310e-03,  4.9488e-02,  1.4745e-02,  1.1499e-04,\n",
       "         3.0479e-03,  9.6153e-02, -2.4290e-02,  1.6899e-02,  1.6000e-03,\n",
       "        -1.6500e-02, -1.6200e-02, -5.5110e-03,  7.5246e-03, -1.4700e-02,\n",
       "         3.0000e-03, -9.9000e-03, -1.1620e-02, -4.0535e-02, -3.9950e-02,\n",
       "         1.7407e-02, -1.6400e-02,  1.2125e-03,  4.4868e-02,  2.5030e-02,\n",
       "        -4.2605e-02, -4.0000e-03, -2.4136e-02, -9.7000e-03, -3.1844e-02,\n",
       "        -5.1000e-03, -1.6110e-02, -1.9730e-02, -1.2860e-02, -1.4470e-02,\n",
       "         4.7214e-03, -1.1868e-02, -1.2668e-02,  1.4155e-02,  1.3185e-02,\n",
       "        -1.9893e-03, -1.1334e-02,  1.4550e-02,  2.2431e-02,  2.6326e-03,\n",
       "         1.3896e-02,  1.3108e-02, -1.4841e-03, -2.4961e-04, -1.4991e-03,\n",
       "        -1.1831e-02, -1.2706e-02, -2.1101e-03, -3.0112e-03, -1.8032e-03,\n",
       "         2.2137e-03,  2.2137e-03, -6.7350e-04, -1.6154e-03,  4.7798e-03,\n",
       "         4.7524e-03,  4.1014e-03,  4.0529e-03,  1.0474e-02,  1.0428e-02,\n",
       "         7.2882e-03,  7.3300e-03,  5.9946e-03,  6.4905e-04,  7.9324e-02,\n",
       "         9.2504e-03,  9.0463e-03,  8.4631e-03,  2.1182e-02,  2.2845e-02,\n",
       "        -5.4901e-04,  9.9000e-03,  4.3688e-02, -6.8956e-03, -2.4417e-03,\n",
       "         2.2431e-02, -6.5240e-02,  6.0000e-03, -7.8200e-02, -3.4800e-02,\n",
       "        -4.4580e-02,  1.7883e-02, -6.3061e-02, -5.9625e-02, -4.4000e-02,\n",
       "        -8.7000e-03,  1.4100e-02,  1.6200e-02,  1.7000e-03, -1.8800e-02,\n",
       "         1.3618e-02,  4.8596e-02,  9.3000e-03, -1.8000e-02,  1.0600e-02,\n",
       "         2.2897e-03,  5.0100e-02,  1.0500e-02,  1.3000e-02, -8.1002e-03,\n",
       "        -8.5971e-03, -4.5000e-02, -2.6900e-02, -9.5000e-03,  1.4800e-02,\n",
       "        -3.3381e-03,  2.3757e-02, -2.0324e-02, -1.2159e-01, -2.7070e-02,\n",
       "        -9.0000e-04, -1.8140e-02, -1.0200e-02,  6.8665e-02, -2.3000e-02,\n",
       "        -6.0300e-02, -2.1387e-02, -2.0000e-04,  5.9991e-02, -2.3911e-03,\n",
       "         4.1645e-02, -1.4044e-03,  3.5108e-02,  3.4897e-02,  3.4343e-02,\n",
       "         2.5661e-03,  2.3553e-03,  1.8322e-03,  1.4624e-03,  1.2143e-03,\n",
       "         6.7882e-04,  2.7200e-02,  5.7978e-03, -1.1000e-03, -1.0000e-03,\n",
       "         3.7552e-02, -1.6000e-02, -9.1000e-03, -6.1000e-02,  1.8010e-02,\n",
       "        -1.0233e-01,  2.8400e-02, -4.4100e-02,  8.6000e-03,  3.8954e-02,\n",
       "         4.2110e-02, -3.4000e-02,  1.3120e-01,  2.0208e-02,  4.7383e-02,\n",
       "         1.3120e-01,  1.3672e-02, -2.6462e-02,  2.5822e-02,  4.6000e-03,\n",
       "         2.3200e-02, -1.3800e-02, -2.1283e-03,  6.2000e-03,  5.5740e-02,\n",
       "        -3.2700e-02, -2.3400e-02,  2.1347e-03, -6.8104e-02, -6.9400e-02,\n",
       "        -9.3000e-03, -9.3000e-03,  6.4122e-03,  6.0000e-03,  1.0000e-02,\n",
       "        -1.0921e-02, -2.5700e-02, -4.6897e-02, -2.4000e-03, -2.4000e-03,\n",
       "        -4.6814e-04, -6.9000e-02,  1.7000e-03, -5.7700e-02, -5.7900e-02,\n",
       "        -5.5300e-02,  9.0901e-04,  3.6590e-02, -2.7933e-02, -6.9000e-03,\n",
       "        -5.4000e-03,  2.6000e-03, -4.1000e-03,  2.2485e-03,  3.5927e-02,\n",
       "         3.4147e-03, -9.0000e-04,  5.6995e-03,  5.6191e-03,  5.8110e-03,\n",
       "         4.9028e-03,  1.0013e-02,  2.0000e-03, -1.9900e-02, -1.9800e-02,\n",
       "        -4.1000e-03,  1.6100e-02,  1.1780e-01, -3.1400e-02,  3.9974e-03,\n",
       "         1.3120e-01, -6.7099e-05,  5.1400e-02,  1.1195e-01,  5.2000e-03,\n",
       "        -1.4192e-02,  6.4000e-03,  2.8466e-02,  2.0207e-02,  6.8676e-03,\n",
       "        -1.2300e-02, -9.0000e-04, -3.3363e-03, -4.1940e-03, -1.2950e-01,\n",
       "        -1.8951e-02,  5.1000e-03,  2.8000e-03,  2.9000e-03, -2.0000e-03,\n",
       "        -1.0662e-01, -1.0537e-01,  1.5000e-03,  4.7874e-02, -2.8700e-02,\n",
       "         1.0351e-02, -2.7190e-02, -1.2300e-02, -1.3200e-02,  1.0200e-02,\n",
       "         6.2000e-03, -1.4000e-03, -3.4000e-03,  2.1600e-02,  1.9378e-02,\n",
       "         9.3663e-03, -1.2300e-02, -1.3500e-02, -1.3600e-02,  2.2068e-02,\n",
       "         2.1458e-02,  1.2891e-02, -4.0500e-02, -1.0000e-04, -1.0000e-02,\n",
       "        -1.1100e-02, -1.0700e-02, -1.1600e-02, -2.2700e-02, -2.3000e-02,\n",
       "        -9.3026e-03,  0.0000e+00, -2.2000e-02, -1.3300e-01,  9.9033e-03,\n",
       "        -4.0300e-02, -1.8900e-02, -3.1000e-03, -9.8183e-03, -3.8697e-02,\n",
       "         7.5500e-02, -7.0000e-04,  3.3254e-02, -1.1200e-02, -8.8000e-03,\n",
       "        -1.0600e-02,  5.2344e-04,  5.7000e-03,  2.6900e-02, -1.6300e-02,\n",
       "         3.0500e-02, -5.0000e-04, -7.3000e-03, -5.7000e-03,  2.1700e-02,\n",
       "         1.0500e-02, -1.4900e-02], dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor(preds.flatten())\n",
    "target = torch.tensor(trues.flatten())\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0819)\n"
     ]
    }
   ],
   "source": [
    "metrics = R2Score()\n",
    "input = torch.tensor(preds.flatten())\n",
    "target = torch.tensor(trues.flatten())\n",
    "metrics.update(input, target)\n",
    "print(metrics.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23 features, sample data, multivariate-predict single, on excess return\n",
    "preds = np.load('results/{}/pred.npy'.format(test_res_path2))\n",
    "trues = np.load('results/{}/true.npy'.format(test_res_path2))\n",
    "mae, mse, _, _, _ = metric(preds[:, :, -1], trues[:, :, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0621)\n"
     ]
    }
   ],
   "source": [
    "for i in range(preds.shape[2]):\n",
    "    metrics = R2Score()\n",
    "    input = torch.tensor(preds[:,:,i].flatten())\n",
    "    target = torch.tensor(trues[:,:,i].flatten())\n",
    "    # target = torch.tensor(trues.flatten())\n",
    "    metrics.update(input, target)\n",
    "    print(metrics.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 features, sample data, multivariate-predict multi, on excess return\n",
    "\n",
    "add_cols = [ \n",
    "            # 'ret',\n",
    "        'aum', \n",
    "        'SENT_', \n",
    "        # 'PTFSBD', \n",
    "        # 'PTFSFX', \n",
    "        # 'PTFSCOM', \n",
    "        # 'em', \n",
    "        # 'sp500', \n",
    "        # 'sizespread', \n",
    "        # 'bondmkt', \n",
    "        # 'creditspread',\n",
    "        # 'SMB', 'HML','RF', 'mom', \n",
    "        # 'con','ipg','tfp','term','def','dei','mkt','lab',\n",
    "        'confeature', 'tfpfeature', 'ipgfeature', 'termfeature', 'deffeature', 'deifeature', 'mktfeature', 'labfeature',\n",
    "        'exret',\n",
    "        ]\n",
    "\n",
    "preds = np.load('results/{}/pred.npy'.format(test_res_path3))\n",
    "trues = np.load('results/{}/true.npy'.format(test_res_path3))\n",
    "mae, mse, _, _, _ = metric(preds[:, :, -1], trues[:, :, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7751) aum\n",
      "tensor(0.6990) SENT_\n",
      "tensor(-0.0483) confeature\n",
      "tensor(0.0119) tfpfeature\n",
      "tensor(-0.0597) ipgfeature\n",
      "tensor(0.4115) termfeature\n",
      "tensor(0.0093) deffeature\n",
      "tensor(-0.0888) deifeature\n",
      "tensor(-0.0922) mktfeature\n",
      "tensor(0.1613) labfeature\n",
      "tensor(-0.0634) exret\n"
     ]
    }
   ],
   "source": [
    "for i in range(preds.shape[2]):\n",
    "    metrics = R2Score()\n",
    "    input = torch.tensor(preds[:,:,i].flatten())\n",
    "    target = torch.tensor(trues[:,:,i].flatten())\n",
    "    # target = torch.tensor(trues.flatten())\n",
    "    metrics.update(input, target)\n",
    "    print(metrics.compute(), add_cols[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
