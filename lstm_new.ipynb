{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(num_layers, x.size(0), hidden_size).to(x.device)\n",
    "        c_0 = torch.zeros(num_layers, x.size(0), hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h_0, c_0))\n",
    "        out = self.fc(out[:, -1, :])  # Take the output from the last time step\n",
    "        return out\n",
    "\n",
    "# Custom dataset class\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, seq_length, target_length, add_cols, target_col):\n",
    "        self.seq_length = seq_length\n",
    "        self.target_length = target_length\n",
    "        self.add_cols = add_cols\n",
    "        self.target_col = target_col\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "\n",
    "        for fund in df['PRODUCTREFERENCE'].unique():\n",
    "            fund_data = df[df['PRODUCTREFERENCE'] == fund].sort_values('date')\n",
    "            if len(fund_data) < seq_length + target_length:\n",
    "                continue\n",
    "            # Normalize the data\n",
    "            scaled_data = self.scaler.fit_transform(fund_data[add_cols])\n",
    "\n",
    "            for i in range(len(fund_data) - seq_length - target_length + 1):\n",
    "                seq_x = scaled_data[i:i+seq_length]\n",
    "                seq_y = fund_data[target_col].iloc[i+seq_length:i+seq_length+target_length].values\n",
    "                self.data.append(seq_x)\n",
    "                self.targets.append(seq_y)\n",
    "        \n",
    "        self.data = np.array(self.data)\n",
    "        self.targets = np.array(self.targets)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_cols = [\n",
    "    'aum', \n",
    "    'SENT_', \n",
    "    'SMB', 'HML', 'RF', 'mom', \n",
    "    'confeature', 'tfpfeature', 'ipgfeature', \n",
    "    'termfeature', 'deffeature', 'deifeature', \n",
    "    'mktfeature', 'labfeature', \n",
    "    'exret'  # Assuming this is the predictor and 'excret' is the target\n",
    "]\n",
    "\n",
    "target_col = 'exret'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/hf/hf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>PRODUCTREFERENCE</th>\n",
       "      <th>exret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>21</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>2023-11-15</td>\n",
       "      <td>21</td>\n",
       "      <td>0.039600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>2023-12-15</td>\n",
       "      <td>21</td>\n",
       "      <td>0.015800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>2023-11-15</td>\n",
       "      <td>29</td>\n",
       "      <td>0.054700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433590</th>\n",
       "      <td>2023-11-15</td>\n",
       "      <td>106517</td>\n",
       "      <td>0.023429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433591</th>\n",
       "      <td>2023-12-15</td>\n",
       "      <td>106517</td>\n",
       "      <td>-0.029457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433883</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>107151</td>\n",
       "      <td>0.126500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433884</th>\n",
       "      <td>2023-11-15</td>\n",
       "      <td>107151</td>\n",
       "      <td>-0.114500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433885</th>\n",
       "      <td>2023-12-15</td>\n",
       "      <td>107151</td>\n",
       "      <td>-0.132900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1574 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  PRODUCTREFERENCE     exret\n",
       "504     2023-10-15                21  0.003200\n",
       "505     2023-11-15                21  0.039600\n",
       "506     2023-12-15                21  0.015800\n",
       "939     2023-10-15                29 -0.059800\n",
       "940     2023-11-15                29  0.054700\n",
       "...            ...               ...       ...\n",
       "433590  2023-11-15            106517  0.023429\n",
       "433591  2023-12-15            106517 -0.029457\n",
       "433883  2023-10-15            107151  0.126500\n",
       "433884  2023-11-15            107151 -0.114500\n",
       "433885  2023-12-15            107151 -0.132900\n",
       "\n",
       "[1574 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = df.copy()\n",
    "test_df = df.loc[df.date >= '2023-10-15', ['date', 'PRODUCTREFERENCE', 'exret']]\n",
    "data_df = data_df.dropna()\n",
    "train_df = data_df[data_df.date <= '2023-09-15']\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = len(add_cols)\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 3  \n",
    "seq_length = 36  # Length of input sequences\n",
    "target_length = 3\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "dataset = TimeSeriesDataset(train_df, seq_length, target_length, add_cols, target_col)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Model, loss, optimizer\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.0012\n",
      "Epoch [2/20], Loss: 0.0007\n",
      "Epoch [3/20], Loss: 0.0011\n",
      "Epoch [4/20], Loss: 0.0007\n",
      "Epoch [5/20], Loss: 0.0003\n",
      "Epoch [6/20], Loss: 0.0011\n",
      "Epoch [7/20], Loss: 0.0006\n",
      "Epoch [8/20], Loss: 0.0006\n",
      "Epoch [9/20], Loss: 0.0004\n",
      "Epoch [10/20], Loss: 0.0004\n",
      "Epoch [11/20], Loss: 0.0008\n",
      "Epoch [12/20], Loss: 0.0005\n",
      "Epoch [13/20], Loss: 0.0008\n",
      "Epoch [14/20], Loss: 0.0004\n",
      "Epoch [15/20], Loss: 0.0005\n",
      "Epoch [16/20], Loss: 0.0004\n",
      "Epoch [17/20], Loss: 0.0004\n",
      "Epoch [18/20], Loss: 0.0005\n",
      "Epoch [19/20], Loss: 0.0004\n",
      "Epoch [20/20], Loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# After training, you can use model.eval() to switch to evaluation mode and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'hidden_128_seqlen_36_20epoch_new.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = df[df.date >= '2023-10-15']\n",
    "\n",
    "# predict_df = data_df[(data_df.date >= '2020-10-15') & ( data_df.date <= '2023-09-15')]\n",
    "predict_df = data_df[data_df.date <= '2023-09-15']\n",
    "count_df = predict_df.groupby(['PRODUCTREFERENCE']).agg({'date': 'count'}).reset_index()\n",
    "predict_df.merge(count_df.loc[count_df.date >= seq_length], on='PRODUCTREFERENCE') \n",
    "funds_to_eval = list(predict_df.merge(test_df, on='PRODUCTREFERENCE', how='inner')['PRODUCTREFERENCE'].unique())\n",
    "predict_df = predict_df[predict_df.PRODUCTREFERENCE.isin(funds_to_eval)]\n",
    "predict_df['series_id'] = predict_df['PRODUCTREFERENCE']\n",
    "\n",
    "# if only including the products with enough history\n",
    "predict_fund_history_count = predict_df.groupby(['PRODUCTREFERENCE']).agg({'date':'count'}).reset_index()\n",
    "predict_funds = list(predict_fund_history_count.loc[predict_fund_history_count.date >= seq_length, 'PRODUCTREFERENCE'])\n",
    "predict_df = predict_df[predict_df.PRODUCTREFERENCE.isin(predict_funds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on training data\n",
    "test_df = data_df[(data_df.date < '2023-10-15') & (data_df.date >= '2023-07-15')]\n",
    "\n",
    "predict_df = data_df[(data_df.date >= '2017-10-15') & ( data_df.date <= '2023-06-15')]\n",
    "count_df = predict_df.groupby(['PRODUCTREFERENCE']).agg({'date': 'count'}).reset_index()\n",
    "predict_df.merge(count_df.loc[count_df.date >= seq_length], on='PRODUCTREFERENCE') \n",
    "funds_to_eval = list(predict_df.merge(test_df, on='PRODUCTREFERENCE', how='inner')['PRODUCTREFERENCE'].unique())\n",
    "predict_df = predict_df[predict_df.PRODUCTREFERENCE.isin(funds_to_eval)]\n",
    "predict_df['series_id'] = predict_df['PRODUCTREFERENCE']\n",
    "\n",
    "# if only including the products with enough history\n",
    "predict_fund_history_count = predict_df.groupby(['PRODUCTREFERENCE']).agg({'date':'count'}).reset_index()\n",
    "predict_funds = list(predict_fund_history_count.loc[predict_fund_history_count.date >= seq_length, 'PRODUCTREFERENCE'])\n",
    "predict_df = predict_df[predict_df.PRODUCTREFERENCE.isin(predict_funds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCTREFERENCE</th>\n",
       "      <th>PRIMARYCATEGORY</th>\n",
       "      <th>date</th>\n",
       "      <th>exret</th>\n",
       "      <th>aum</th>\n",
       "      <th>aum24m</th>\n",
       "      <th>aumrec</th>\n",
       "      <th>PTFSBD</th>\n",
       "      <th>PTFSFX</th>\n",
       "      <th>PTFSCOM</th>\n",
       "      <th>...</th>\n",
       "      <th>labbeta</th>\n",
       "      <th>confeature</th>\n",
       "      <th>tfpfeature</th>\n",
       "      <th>ipgfeature</th>\n",
       "      <th>termfeature</th>\n",
       "      <th>deffeature</th>\n",
       "      <th>deifeature</th>\n",
       "      <th>mktfeature</th>\n",
       "      <th>labfeature</th>\n",
       "      <th>series_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>29</td>\n",
       "      <td>Long/Short Equity Hedge</td>\n",
       "      <td>2017-10-15</td>\n",
       "      <td>-0.008000</td>\n",
       "      <td>14962687.0</td>\n",
       "      <td>1.486074e+07</td>\n",
       "      <td>1.769472e+07</td>\n",
       "      <td>-0.1554</td>\n",
       "      <td>-0.0239</td>\n",
       "      <td>-0.0592</td>\n",
       "      <td>...</td>\n",
       "      <td>1.566517</td>\n",
       "      <td>-0.007233</td>\n",
       "      <td>-0.000705</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>8.322672e-18</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.018559</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>29</td>\n",
       "      <td>Long/Short Equity Hedge</td>\n",
       "      <td>2017-11-15</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>15220348.0</td>\n",
       "      <td>1.484563e+07</td>\n",
       "      <td>1.768204e+07</td>\n",
       "      <td>-0.0806</td>\n",
       "      <td>-0.2678</td>\n",
       "      <td>-0.1222</td>\n",
       "      <td>...</td>\n",
       "      <td>2.731222</td>\n",
       "      <td>-0.006302</td>\n",
       "      <td>-0.003527</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>-6.658714e-03</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>0.023714</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>29</td>\n",
       "      <td>Long/Short Equity Hedge</td>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>15402024.0</td>\n",
       "      <td>1.486273e+07</td>\n",
       "      <td>1.767040e+07</td>\n",
       "      <td>-0.1131</td>\n",
       "      <td>-0.1190</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>...</td>\n",
       "      <td>2.792083</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>-0.003258</td>\n",
       "      <td>-0.001630</td>\n",
       "      <td>-3.375621e-03</td>\n",
       "      <td>-0.001530</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>29</td>\n",
       "      <td>Long/Short Equity Hedge</td>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>15759775.0</td>\n",
       "      <td>1.492182e+07</td>\n",
       "      <td>1.766070e+07</td>\n",
       "      <td>0.2099</td>\n",
       "      <td>0.5127</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>...</td>\n",
       "      <td>2.262481</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>1.352823e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008841</td>\n",
       "      <td>0.039748</td>\n",
       "      <td>0.012361</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>29</td>\n",
       "      <td>Long/Short Equity Hedge</td>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>-0.011400</td>\n",
       "      <td>13859601.0</td>\n",
       "      <td>1.492035e+07</td>\n",
       "      <td>1.764151e+07</td>\n",
       "      <td>-0.0921</td>\n",
       "      <td>-0.0844</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.468317</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>1.460951e-03</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>-0.001518</td>\n",
       "      <td>-0.023943</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433580</th>\n",
       "      <td>106517</td>\n",
       "      <td>Multi-Strategy</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>19200000.0</td>\n",
       "      <td>1.899633e+07</td>\n",
       "      <td>3.666113e+07</td>\n",
       "      <td>-0.1830</td>\n",
       "      <td>-0.1239</td>\n",
       "      <td>-0.1639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038081</td>\n",
       "      <td>0.004457</td>\n",
       "      <td>0.008856</td>\n",
       "      <td>0.011854</td>\n",
       "      <td>6.185814e-03</td>\n",
       "      <td>-0.006282</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.010210</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>106517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433581</th>\n",
       "      <td>106517</td>\n",
       "      <td>Multi-Strategy</td>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>-0.022241</td>\n",
       "      <td>19100000.0</td>\n",
       "      <td>1.897007e+07</td>\n",
       "      <td>3.640662e+07</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>-0.1890</td>\n",
       "      <td>-0.0560</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046249</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>-0.003087</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>2.874895e-03</td>\n",
       "      <td>0.009152</td>\n",
       "      <td>0.004531</td>\n",
       "      <td>-0.003530</td>\n",
       "      <td>0.007482</td>\n",
       "      <td>106517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433583</th>\n",
       "      <td>106517</td>\n",
       "      <td>Multi-Strategy</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>0.027229</td>\n",
       "      <td>17400000.0</td>\n",
       "      <td>1.877012e+07</td>\n",
       "      <td>3.613510e+07</td>\n",
       "      <td>-0.1711</td>\n",
       "      <td>-0.0147</td>\n",
       "      <td>-0.0459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713583</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>1.730460e-04</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.005818</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>106517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433584</th>\n",
       "      <td>106517</td>\n",
       "      <td>Multi-Strategy</td>\n",
       "      <td>2023-05-15</td>\n",
       "      <td>-0.056724</td>\n",
       "      <td>16800000.0</td>\n",
       "      <td>1.867162e+07</td>\n",
       "      <td>3.586277e+07</td>\n",
       "      <td>-0.1270</td>\n",
       "      <td>-0.0919</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>-0.001138</td>\n",
       "      <td>3.759342e-04</td>\n",
       "      <td>-0.004719</td>\n",
       "      <td>-0.002436</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>106517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433585</th>\n",
       "      <td>106517</td>\n",
       "      <td>Multi-Strategy</td>\n",
       "      <td>2023-06-15</td>\n",
       "      <td>0.020602</td>\n",
       "      <td>16480000.0</td>\n",
       "      <td>1.849562e+07</td>\n",
       "      <td>3.559357e+07</td>\n",
       "      <td>-0.1429</td>\n",
       "      <td>-0.0359</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>...</td>\n",
       "      <td>1.906140</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>-0.001614</td>\n",
       "      <td>-0.003789</td>\n",
       "      <td>-2.196595e-03</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>0.018352</td>\n",
       "      <td>0.006218</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>106517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19306 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PRODUCTREFERENCE          PRIMARYCATEGORY        date     exret  \\\n",
       "867                   29  Long/Short Equity Hedge  2017-10-15 -0.008000   \n",
       "868                   29  Long/Short Equity Hedge  2017-11-15  0.019000   \n",
       "869                   29  Long/Short Equity Hedge  2017-12-15  0.011500   \n",
       "870                   29  Long/Short Equity Hedge  2018-01-15  0.019200   \n",
       "871                   29  Long/Short Equity Hedge  2018-02-15 -0.011400   \n",
       "...                  ...                      ...         ...       ...   \n",
       "433580            106517           Multi-Strategy  2023-01-15  0.007359   \n",
       "433581            106517           Multi-Strategy  2023-02-15 -0.022241   \n",
       "433583            106517           Multi-Strategy  2023-04-15  0.027229   \n",
       "433584            106517           Multi-Strategy  2023-05-15 -0.056724   \n",
       "433585            106517           Multi-Strategy  2023-06-15  0.020602   \n",
       "\n",
       "               aum        aum24m        aumrec  PTFSBD  PTFSFX  PTFSCOM  ...  \\\n",
       "867     14962687.0  1.486074e+07  1.769472e+07 -0.1554 -0.0239  -0.0592  ...   \n",
       "868     15220348.0  1.484563e+07  1.768204e+07 -0.0806 -0.2678  -0.1222  ...   \n",
       "869     15402024.0  1.486273e+07  1.767040e+07 -0.1131 -0.1190   0.0084  ...   \n",
       "870     15759775.0  1.492182e+07  1.766070e+07  0.2099  0.5127   0.0045  ...   \n",
       "871     13859601.0  1.492035e+07  1.764151e+07 -0.0921 -0.0844   0.0392  ...   \n",
       "...            ...           ...           ...     ...     ...      ...  ...   \n",
       "433580  19200000.0  1.899633e+07  3.666113e+07 -0.1830 -0.1239  -0.1639  ...   \n",
       "433581  19100000.0  1.897007e+07  3.640662e+07  0.0588 -0.1890  -0.0560  ...   \n",
       "433583  17400000.0  1.877012e+07  3.613510e+07 -0.1711 -0.0147  -0.0459  ...   \n",
       "433584  16800000.0  1.867162e+07  3.586277e+07 -0.1270 -0.0919   0.0491  ...   \n",
       "433585  16480000.0  1.849562e+07  3.559357e+07 -0.1429 -0.0359   0.1372  ...   \n",
       "\n",
       "         labbeta  confeature  tfpfeature  ipgfeature   termfeature  \\\n",
       "867     1.566517   -0.007233   -0.000705    0.000230  8.322672e-18   \n",
       "868     2.731222   -0.006302   -0.003527    0.002271 -6.658714e-03   \n",
       "869     2.792083   -0.001598   -0.003258   -0.001630 -3.375621e-03   \n",
       "870     2.262481    0.002334    0.001401    0.003760  1.352823e-04   \n",
       "871     1.468317    0.004777    0.002624    0.001939  1.460951e-03   \n",
       "...          ...         ...         ...         ...           ...   \n",
       "433580  0.038081    0.004457    0.008856    0.011854  6.185814e-03   \n",
       "433581  1.046249    0.004883   -0.003087    0.000270  2.874895e-03   \n",
       "433583  0.713583    0.004134    0.000197    0.002232  1.730460e-04   \n",
       "433584  0.675415    0.000000    0.001681   -0.001138  3.759342e-04   \n",
       "433585  1.906140    0.003690   -0.001614   -0.003789 -2.196595e-03   \n",
       "\n",
       "        deffeature  deifeature  mktfeature  labfeature  series_id  \n",
       "867      -0.000151    0.002828    0.018559    0.005830         29  \n",
       "868       0.003209   -0.000032    0.023714    0.009531         29  \n",
       "869      -0.001530    0.000903    0.008126    0.009785         29  \n",
       "870       0.000000   -0.008841    0.039748    0.012361         29  \n",
       "871       0.001742   -0.001518   -0.023943    0.003629         29  \n",
       "...            ...         ...         ...         ...        ...  \n",
       "433580   -0.006282    0.000627    0.010210    0.000272     106517  \n",
       "433581    0.009152    0.004531   -0.003530    0.007482     106517  \n",
       "433583    0.006472    0.005818    0.000497    0.003052     106517  \n",
       "433584   -0.004719   -0.002436    0.000357    0.002889     106517  \n",
       "433585   -0.001130    0.018352    0.006218    0.008152     106517  \n",
       "\n",
       "[19306 rows x 79 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMModel(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_size=output_size)\n",
    "\n",
    "# Load the saved model state dict\n",
    "model.load_state_dict(torch.load('hidden_128_seqlen_36_50epoch_best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01923302 0.06568377 0.04887139]\n",
      "[0.0011267  0.07217118 0.04881562]\n",
      "[0.02153692 0.06475216 0.04931376]\n",
      "[0.00981168 0.07111658 0.04862896]\n",
      "[0.02090641 0.06410188 0.05006267]\n",
      "[0.00926523 0.07136723 0.04808789]\n",
      "[0.00946084 0.07017653 0.04558769]\n",
      "[0.00490828 0.07195754 0.04732652]\n",
      "[0.00989357 0.06664696 0.04700595]\n",
      "[0.01735542 0.06495791 0.04776597]\n",
      "[0.00374131 0.06888176 0.04708175]\n",
      "[0.00989173 0.06947912 0.04338474]\n",
      "[-0.01707276  0.07447472  0.04697167]\n",
      "[0.00934545 0.0652249  0.04677149]\n",
      "[-0.00076534  0.06912328  0.0470513 ]\n",
      "[-0.00161177  0.069077    0.04783442]\n",
      "[-0.00158765  0.07276247  0.05108691]\n",
      "[-0.00107143  0.06777108  0.0477992 ]\n",
      "[0.00898386 0.06476824 0.04767713]\n",
      "[0.01289042 0.06526019 0.04598769]\n",
      "[0.01768419 0.06342503 0.04722811]\n",
      "[0.0064601  0.06910073 0.04794075]\n",
      "[0.00783306 0.07008462 0.04805417]\n",
      "[0.0369009  0.06462419 0.05740889]\n",
      "[0.00487005 0.07056535 0.04642818]\n",
      "[0.0079183  0.06989478 0.04826371]\n",
      "[0.00439057 0.07260107 0.05080303]\n",
      "[0.01582255 0.06918787 0.04963469]\n",
      "[0.01329212 0.06553343 0.0469037 ]\n",
      "[-0.00248781  0.06901436  0.04791134]\n",
      "[0.00243551 0.0725865  0.04880318]\n",
      "[0.00547797 0.06825526 0.04685514]\n",
      "[0.01923594 0.06515309 0.04962447]\n",
      "[0.0141682  0.06705304 0.04957999]\n",
      "[0.02621552 0.06805248 0.05287147]\n",
      "[0.01617361 0.07168907 0.05053775]\n",
      "[0.00545894 0.06764224 0.04818633]\n",
      "[0.02109797 0.06600777 0.05247247]\n",
      "[0.0065336  0.06964312 0.04831541]\n",
      "[0.0365719  0.05661631 0.05443919]\n",
      "[0.0287767  0.06549087 0.05716596]\n",
      "[0.01420258 0.06921436 0.04691383]\n",
      "[0.00659109 0.06866965 0.04819918]\n",
      "[0.01152522 0.06990962 0.0489435 ]\n",
      "[0.01744469 0.06438733 0.0479507 ]\n",
      "[0.03732314 0.06613295 0.05503421]\n",
      "[0.0153817  0.06470013 0.05020313]\n",
      "[0.01949486 0.06535296 0.04807637]\n",
      "[0.01555576 0.06914163 0.04779644]\n",
      "[0.01862022 0.0702609  0.04850829]\n",
      "[0.02237514 0.06591138 0.04828839]\n",
      "[0.01751158 0.06584889 0.04799257]\n",
      "[0.02115056 0.06690855 0.04898721]\n",
      "[0.01753221 0.06836404 0.05091399]\n",
      "[0.01089609 0.06886759 0.04929212]\n",
      "[0.02227941 0.06555104 0.05022937]\n",
      "[0.00644906 0.06813586 0.04688612]\n",
      "[0.01773557 0.07080904 0.0508075 ]\n",
      "[0.02781665 0.06363909 0.05282987]\n",
      "[0.02013984 0.06515121 0.04855677]\n",
      "[0.02065402 0.06796396 0.04721502]\n",
      "[0.0166948  0.06755744 0.04653859]\n",
      "[0.01984328 0.06957298 0.04951368]\n",
      "[0.01177144 0.06552233 0.04667165]\n",
      "[0.01220213 0.06807575 0.04709934]\n",
      "[0.01737408 0.06746276 0.05386833]\n",
      "[0.0103614  0.06751914 0.04786465]\n",
      "[0.00727247 0.06724337 0.0528523 ]\n",
      "[0.02102789 0.06619064 0.05300528]\n",
      "[0.01225888 0.06493119 0.04721802]\n",
      "[0.01037022 0.06996749 0.04873314]\n",
      "[0.03554419 0.06391384 0.05370514]\n",
      "[0.02155762 0.06474702 0.0492988 ]\n",
      "[0.01942172 0.04968636 0.04581707]\n",
      "[0.01681934 0.06618184 0.04777914]\n",
      "[0.00394989 0.06984006 0.04705705]\n",
      "[0.00192663 0.07204923 0.0516987 ]\n",
      "[0.01115545 0.06975887 0.05265051]\n",
      "[0.02037521 0.06917855 0.05065525]\n",
      "[0.00804682 0.07010007 0.04837093]\n",
      "[0.03461573 0.06469403 0.05358028]\n",
      "[0.01478403 0.06865773 0.04803054]\n",
      "[0.00817876 0.06862919 0.05007976]\n",
      "[0.0104944  0.07167426 0.05227029]\n",
      "[0.01624501 0.0685538  0.05004794]\n",
      "[0.0004199  0.07286257 0.04941834]\n",
      "[-0.00429258  0.06556424  0.04703151]\n",
      "[0.00501597 0.06993303 0.0514715 ]\n",
      "[-0.00321424  0.06728797  0.04813962]\n",
      "[0.01083145 0.06506899 0.04788555]\n",
      "[0.01172072 0.07005828 0.04733704]\n",
      "[0.01511005 0.06788988 0.04910079]\n",
      "[0.01793592 0.06724334 0.05020787]\n",
      "[0.01500893 0.06849435 0.04926621]\n",
      "[0.02664879 0.06499398 0.05179898]\n",
      "[0.00983244 0.06994583 0.04740679]\n",
      "[0.0235987  0.06301302 0.05598396]\n",
      "[0.02291122 0.07089071 0.05194404]\n",
      "[0.03117688 0.06420659 0.0524436 ]\n",
      "[0.01856898 0.06863388 0.04827555]\n",
      "[0.01594831 0.06523895 0.0501856 ]\n",
      "[0.01239104 0.06915289 0.04787937]\n",
      "[0.00694164 0.06774795 0.04708036]\n",
      "[0.00899777 0.06718467 0.04820637]\n",
      "[0.00637631 0.06655784 0.04731226]\n",
      "[0.00726361 0.06806874 0.0479985 ]\n",
      "[0.01270429 0.06688508 0.0512638 ]\n",
      "[0.01007666 0.06765912 0.04821643]\n",
      "[-0.00028046  0.0736772   0.04784125]\n",
      "[0.01260173 0.06573352 0.04951071]\n",
      "[0.02081325 0.06598894 0.05140862]\n",
      "[0.02691727 0.06665342 0.05734474]\n",
      "[0.00981997 0.06793091 0.04759164]\n",
      "[0.01149122 0.06948459 0.04878497]\n",
      "[0.00914009 0.07120861 0.04863964]\n",
      "[0.02746413 0.06320837 0.0483887 ]\n",
      "[0.00260213 0.07160226 0.04782897]\n",
      "[0.0179704  0.06680636 0.05048058]\n",
      "[0.019085   0.06774949 0.04803227]\n",
      "[0.01251332 0.0598515  0.04887163]\n",
      "[0.00986784 0.06721202 0.04674852]\n",
      "[0.0248325  0.06466977 0.04743003]\n",
      "[0.01306269 0.07121803 0.04919726]\n",
      "[0.00613476 0.07003086 0.04752998]\n",
      "[0.01074252 0.07188613 0.05026382]\n",
      "[0.0194244  0.06693441 0.04925053]\n",
      "[0.01170239 0.07377027 0.04658432]\n",
      "[0.01643319 0.06929635 0.04976318]\n",
      "[0.03349232 0.06017718 0.05448671]\n",
      "[0.00802424 0.06863829 0.04851345]\n",
      "[0.00873452 0.06852384 0.0487378 ]\n",
      "[0.00905574 0.06630442 0.05465978]\n",
      "[0.00587583 0.07129017 0.04724484]\n",
      "[0.02333879 0.06452566 0.05236058]\n",
      "[0.00813689 0.06505037 0.04823154]\n",
      "[0.00754219 0.07244995 0.04919455]\n",
      "[0.02581565 0.06334961 0.04885916]\n",
      "[0.00033405 0.07482706 0.04969961]\n",
      "[0.01341281 0.07026308 0.05148124]\n",
      "[0.03439247 0.06304997 0.05368808]\n",
      "[0.03400248 0.06278589 0.0539197 ]\n",
      "[0.02407542 0.06622186 0.05193394]\n",
      "[0.0297653  0.0652663  0.05112489]\n",
      "[0.00604861 0.06851804 0.04962514]\n",
      "[0.0117698  0.07031661 0.05027661]\n",
      "[0.01184435 0.06903447 0.05130965]\n",
      "[0.00840232 0.06854865 0.05090547]\n",
      "[0.00586649 0.06917448 0.04808884]\n",
      "[0.01393529 0.07022784 0.05008194]\n",
      "[0.02160498 0.06490704 0.04757516]\n",
      "[0.01013305 0.06816229 0.04656236]\n",
      "[0.01952359 0.06511298 0.05526988]\n",
      "[0.00359069 0.07047766 0.04555609]\n",
      "[0.02308945 0.07265191 0.05352891]\n",
      "[0.02218772 0.06413879 0.05372727]\n",
      "[0.01211593 0.06611986 0.04710064]\n",
      "[0.01173591 0.06618422 0.04693179]\n",
      "[0.01498521 0.06498472 0.04731027]\n",
      "[0.01935453 0.06390962 0.04826656]\n",
      "[0.00854081 0.07162391 0.05009506]\n",
      "[-0.00045763  0.0708358   0.0477784 ]\n",
      "[-0.00380618  0.07207081  0.04726898]\n",
      "[0.01185081 0.06643883 0.04851153]\n",
      "[0.00262353 0.07269089 0.0471349 ]\n",
      "[0.01897443 0.06371852 0.05512927]\n",
      "[0.00951223 0.07019632 0.05235043]\n",
      "[0.0287698  0.06460911 0.05260231]\n",
      "[0.0087337 0.0681425 0.0481137]\n",
      "[0.02609628 0.06690962 0.05057982]\n",
      "[-0.00664533  0.07232797  0.04559027]\n",
      "[0.03426673 0.0629704  0.05526014]\n",
      "[0.01177791 0.07000966 0.04929634]\n",
      "[0.032725   0.0639112  0.05293445]\n",
      "[0.02793944 0.06489931 0.05212026]\n",
      "[0.03291466 0.06350189 0.0528702 ]\n",
      "[0.01991167 0.06123074 0.05056353]\n",
      "[0.0339868  0.06021141 0.0518145 ]\n",
      "[0.00975442 0.0687955  0.04554402]\n",
      "[0.01289689 0.06702076 0.04669201]\n",
      "[0.01651872 0.06301944 0.04647499]\n",
      "[0.00394409 0.06240138 0.04708792]\n",
      "[0.02006719 0.06247772 0.0470536 ]\n",
      "[0.00372549 0.07293495 0.04944527]\n",
      "[0.01850961 0.06132372 0.0522496 ]\n",
      "[0.03153077 0.06419763 0.05261576]\n",
      "[0.02755547 0.06239768 0.05073711]\n",
      "[0.00048647 0.06863102 0.03997739]\n",
      "[0.01515241 0.06459016 0.04808313]\n",
      "[0.03195151 0.06144547 0.05278084]\n",
      "[0.01324974 0.06797616 0.04793385]\n",
      "[-0.00011102  0.07185381  0.04789358]\n",
      "[0.01980082 0.06069115 0.05512689]\n",
      "[0.00284914 0.07325448 0.04669091]\n",
      "[0.01414244 0.0709982  0.05043878]\n",
      "[0.01882285 0.0678365  0.05147547]\n",
      "[0.02433949 0.06462663 0.05012534]\n",
      "[0.02418221 0.06370433 0.05080191]\n",
      "[0.00205073 0.06981991 0.04584546]\n",
      "[0.03278518 0.06586475 0.05019921]\n",
      "[0.00899363 0.0827268  0.05647104]\n",
      "[0.01623053 0.06487399 0.0479603 ]\n",
      "[0.03398653 0.0628709  0.05388713]\n",
      "[0.02692878 0.06674704 0.05739028]\n",
      "[0.00932075 0.06966637 0.04821105]\n",
      "[0.01808008 0.06548822 0.05057395]\n",
      "[0.00244335 0.07150048 0.04736113]\n",
      "[0.02988972 0.06011415 0.05316787]\n",
      "[-0.00290124  0.06612346  0.04518086]\n",
      "[0.00561655 0.07363962 0.04951317]\n",
      "[0.01037489 0.06991804 0.04753461]\n",
      "[0.038829   0.06372797 0.05496836]\n",
      "[0.02578633 0.05696735 0.05084382]\n",
      "[0.02532971 0.06414725 0.05098586]\n",
      "[0.03662578 0.06747538 0.05180665]\n",
      "[0.02458587 0.06500539 0.05032552]\n",
      "[0.03006516 0.06659925 0.05646254]\n",
      "[0.01992434 0.07067224 0.05056939]\n",
      "[0.00843754 0.06981266 0.05089546]\n",
      "[0.01329247 0.06264302 0.05167172]\n",
      "[0.01791268 0.07593541 0.05322856]\n",
      "[0.02128397 0.06743605 0.05399943]\n",
      "[0.02668656 0.05856039 0.05127259]\n",
      "[-0.00122737  0.07516397  0.05144392]\n",
      "[0.03421544 0.06132378 0.05060214]\n",
      "[0.00735454 0.07185882 0.04895511]\n",
      "[0.00703956 0.07172086 0.04872289]\n",
      "[0.01937757 0.05914396 0.0490366 ]\n",
      "[0.0084437  0.07113384 0.05082562]\n",
      "[0.00774754 0.07185537 0.05063915]\n",
      "[0.01241485 0.0690392  0.04692467]\n",
      "[0.01604739 0.0649149  0.05071752]\n",
      "[0.00563077 0.06957617 0.04661603]\n",
      "[0.00315809 0.07007945 0.0508796 ]\n",
      "[0.00162246 0.06743584 0.04903621]\n",
      "[0.03654946 0.06434286 0.05551931]\n",
      "[0.01228059 0.06991294 0.04736309]\n",
      "[0.02029511 0.06763624 0.04964572]\n",
      "[-0.00133356  0.06686319  0.05251689]\n",
      "[0.00265293 0.07105672 0.050667  ]\n",
      "[0.01534537 0.06791276 0.04673188]\n",
      "[0.02015648 0.06042612 0.04713015]\n",
      "[0.0323309  0.06230938 0.05327205]\n",
      "[0.03011046 0.06237859 0.05429833]\n",
      "[-0.00298317  0.07292063  0.04946009]\n",
      "[0.02378281 0.07104506 0.05304127]\n",
      "[0.00576155 0.07305108 0.04910343]\n",
      "[0.02551907 0.06341147 0.05255817]\n",
      "[0.02617818 0.06368335 0.05272241]\n",
      "[0.00074723 0.07151905 0.05109521]\n",
      "[0.02115439 0.06484039 0.04751883]\n",
      "[0.01925418 0.06598306 0.04982189]\n",
      "[0.01818725 0.07064845 0.04965025]\n",
      "[0.01074272 0.0704968  0.04575979]\n",
      "[0.00932114 0.06797603 0.04816245]\n",
      "[0.01242158 0.06944498 0.04965698]\n",
      "[0.01699342 0.06701372 0.04898324]\n",
      "[0.00833892 0.07015651 0.04792619]\n",
      "[0.01069297 0.06460951 0.04764421]\n",
      "[0.00555754 0.07029012 0.04595553]\n",
      "[0.00040408 0.07358755 0.04516619]\n",
      "[0.00095867 0.06887132 0.04504719]\n",
      "[0.0097185  0.06918177 0.04804827]\n",
      "[0.02666732 0.06337285 0.04969294]\n",
      "[0.00844536 0.0709928  0.05148502]\n",
      "[0.03619835 0.06320959 0.05252231]\n",
      "[0.00420024 0.06975543 0.04880511]\n",
      "[0.00405505 0.06430594 0.04906029]\n",
      "[0.01002379 0.07066534 0.04927545]\n",
      "[0.00820689 0.07039911 0.04715728]\n",
      "[0.01766968 0.06934731 0.05335439]\n",
      "[0.00543794 0.07131371 0.04721681]\n",
      "[0.01026909 0.0695456  0.05119472]\n",
      "[0.0084751  0.06931141 0.04628779]\n",
      "[0.00075748 0.06893385 0.04111953]\n",
      "[-0.00228537  0.07046293  0.04145992]\n",
      "[0.02412123 0.06609458 0.05103261]\n",
      "[0.006336   0.07201687 0.04902352]\n",
      "[0.01309029 0.06810645 0.04778596]\n",
      "[0.02859385 0.06353194 0.05845271]\n",
      "[0.01034799 0.06750964 0.05276328]\n",
      "[0.03339711 0.06103698 0.05354831]\n",
      "[0.02734664 0.06269272 0.05065644]\n",
      "[0.01177153 0.06892903 0.0462562 ]\n",
      "[0.01285267 0.06787328 0.04944753]\n",
      "[0.02706184 0.06489304 0.05252712]\n",
      "[0.00591099 0.06717376 0.0496195 ]\n",
      "[0.02201029 0.07281327 0.05347019]\n",
      "[0.00605176 0.06770678 0.044267  ]\n",
      "[0.0262993  0.06309459 0.05339886]\n",
      "[0.01496165 0.06765646 0.04921814]\n",
      "[-0.00702274  0.07968047  0.04472033]\n",
      "[0.01020484 0.06594755 0.04840681]\n",
      "[0.00027012 0.06611229 0.04667041]\n",
      "[-0.00073052  0.06527284  0.04686033]\n",
      "[0.00811093 0.06867476 0.04959358]\n",
      "     PRODUCTREFERENCE  Prediction_Period_1  Prediction_Period_2  \\\n",
      "0                  29             0.019233             0.065684   \n",
      "1                  35             0.001127             0.072171   \n",
      "2                 441             0.021537             0.064752   \n",
      "3                 727             0.009812             0.071117   \n",
      "4                 814             0.020906             0.064102   \n",
      "..                ...                  ...                  ...   \n",
      "290            106446            -0.007023             0.079680   \n",
      "291            106455             0.010205             0.065948   \n",
      "292            106484             0.000270             0.066112   \n",
      "293            106485            -0.000731             0.065273   \n",
      "294            106517             0.008111             0.068675   \n",
      "\n",
      "     Prediction_Period_3  \n",
      "0               0.048871  \n",
      "1               0.048816  \n",
      "2               0.049314  \n",
      "3               0.048629  \n",
      "4               0.050063  \n",
      "..                   ...  \n",
      "290             0.044720  \n",
      "291             0.048407  \n",
      "292             0.046670  \n",
      "293             0.046860  \n",
      "294             0.049594  \n",
      "\n",
      "[295 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Iterate over each unique PRODUCTREFERENCE\n",
    "for product_reference in predict_df['PRODUCTREFERENCE'].unique():\n",
    "    \n",
    "    # Extract the latest sequence for this PRODUCTREFERENCE\n",
    "    fund_data = predict_df[predict_df['PRODUCTREFERENCE'] == product_reference].sort_values('date')\n",
    "\n",
    "    # Skip this PRODUCTREFERENCE if there's not enough data\n",
    "    if len(fund_data) < seq_length:\n",
    "        continue\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # option 1\n",
    "    # scaled_data = scaler.fit_transform(fund_data[add_cols])\n",
    "    # scaled_fund_data = scaled_data[-seq_length:]\n",
    "    \n",
    "    # option 2\n",
    "    scaler.fit(fund_data[add_cols])\n",
    "    scaled_fund_data = scaler.transform(fund_data[add_cols].tail(seq_length))\n",
    "\n",
    "    # option 3\n",
    "\n",
    "\n",
    "    # input data\n",
    "    input_data = np.expand_dims(scaled_fund_data, axis=0)  # Add batch dimension\n",
    "    # Convert to PyTorch tensor\n",
    "    input_tensor = torch.tensor(input_data, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    # Switch model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_tensor)\n",
    "\n",
    "    # Convert prediction to numpy array\n",
    "    predicted_values = prediction.numpy().flatten()\n",
    "    \n",
    "    print(predicted_values)\n",
    "\n",
    "    # (Optional) Inverse scale the prediction if you scaled the data\n",
    "    # predicted_values_original_scale = scaler.inverse_transform(predicted_values.reshape(-1, 1)).flatten()\n",
    "    predicted_values_original_scale = predicted_values\n",
    "\n",
    "    # Store the result\n",
    "    results.append({\n",
    "        'PRODUCTREFERENCE': product_reference,\n",
    "        'Prediction_Period_1': predicted_values_original_scale[0],\n",
    "        'Prediction_Period_2': predicted_values_original_scale[1],\n",
    "        'Prediction_Period_3': predicted_values_original_scale[2]\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame for easier handling\n",
    "predictions_df = pd.DataFrame(results)\n",
    "\n",
    "# Display or save the predictions\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCTREFERENCE</th>\n",
       "      <th>Prediction_Period_1</th>\n",
       "      <th>Prediction_Period_2</th>\n",
       "      <th>Prediction_Period_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>0.019233</td>\n",
       "      <td>0.065684</td>\n",
       "      <td>0.048871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.072171</td>\n",
       "      <td>0.048816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441</td>\n",
       "      <td>0.021537</td>\n",
       "      <td>0.064752</td>\n",
       "      <td>0.049314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>727</td>\n",
       "      <td>0.009812</td>\n",
       "      <td>0.071117</td>\n",
       "      <td>0.048629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>814</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.064102</td>\n",
       "      <td>0.050063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>106446</td>\n",
       "      <td>-0.007023</td>\n",
       "      <td>0.079680</td>\n",
       "      <td>0.044720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>106455</td>\n",
       "      <td>0.010205</td>\n",
       "      <td>0.065948</td>\n",
       "      <td>0.048407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>106484</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.066112</td>\n",
       "      <td>0.046670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>106485</td>\n",
       "      <td>-0.000731</td>\n",
       "      <td>0.065273</td>\n",
       "      <td>0.046860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>106517</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.068675</td>\n",
       "      <td>0.049594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PRODUCTREFERENCE  Prediction_Period_1  Prediction_Period_2  \\\n",
       "0                  29             0.019233             0.065684   \n",
       "1                  35             0.001127             0.072171   \n",
       "2                 441             0.021537             0.064752   \n",
       "3                 727             0.009812             0.071117   \n",
       "4                 814             0.020906             0.064102   \n",
       "..                ...                  ...                  ...   \n",
       "290            106446            -0.007023             0.079680   \n",
       "291            106455             0.010205             0.065948   \n",
       "292            106484             0.000270             0.066112   \n",
       "293            106485            -0.000731             0.065273   \n",
       "294            106517             0.008111             0.068675   \n",
       "\n",
       "     Prediction_Period_3  \n",
       "0               0.048871  \n",
       "1               0.048816  \n",
       "2               0.049314  \n",
       "3               0.048629  \n",
       "4               0.050063  \n",
       "..                   ...  \n",
       "290             0.044720  \n",
       "291             0.048407  \n",
       "292             0.046670  \n",
       "293             0.046860  \n",
       "294             0.049594  \n",
       "\n",
       "[295 rows x 4 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCTREFERENCE</th>\n",
       "      <th>exret_x</th>\n",
       "      <th>exret_y</th>\n",
       "      <th>exret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>-0.064300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.002610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>-0.004000</td>\n",
       "      <td>-0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>727</td>\n",
       "      <td>-0.014238</td>\n",
       "      <td>-0.005774</td>\n",
       "      <td>0.005192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>814</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>-0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>105997</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>-0.014700</td>\n",
       "      <td>-0.017900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>106455</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>-0.014100</td>\n",
       "      <td>-0.019300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>106484</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>-0.062100</td>\n",
       "      <td>0.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>106485</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>-0.059300</td>\n",
       "      <td>-0.062400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>106517</td>\n",
       "      <td>0.030605</td>\n",
       "      <td>0.032693</td>\n",
       "      <td>0.008251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PRODUCTREFERENCE   exret_x   exret_y     exret\n",
       "0                  29  0.046100  0.002400 -0.064300\n",
       "1                  35  0.002600  0.010800  0.002610\n",
       "2                 441  0.000800 -0.004000 -0.014400\n",
       "3                 727 -0.014238 -0.005774  0.005192\n",
       "4                 814  0.054600  0.018400 -0.000400\n",
       "..                ...       ...       ...       ...\n",
       "274            105997  0.009600 -0.014700 -0.017900\n",
       "275            106455  0.003100 -0.014100 -0.019300\n",
       "276            106484  0.059200 -0.062100  0.053100\n",
       "277            106485  0.059200 -0.059300 -0.062400\n",
       "278            106517  0.030605  0.032693  0.008251\n",
       "\n",
       "[279 rows x 4 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred_1 = test_df.loc[test_df.date == '2023-10-15', ['PRODUCTREFERENCE', 'exret']]\n",
    "# pred_2 = test_df.loc[test_df.date == '2023-11-15', ['PRODUCTREFERENCE', 'exret']]\n",
    "# pred_3 = test_df.loc[test_df.date == '2023-12-15', ['PRODUCTREFERENCE', 'exret']]\n",
    "pred_1 = test_df.loc[test_df.date == '2023-07-15', ['PRODUCTREFERENCE', 'exret']]\n",
    "pred_2 = test_df.loc[test_df.date == '2023-08-15', ['PRODUCTREFERENCE', 'exret']]\n",
    "pred_3 = test_df.loc[test_df.date == '2023-09-15', ['PRODUCTREFERENCE', 'exret']]\n",
    "\n",
    "\n",
    "\n",
    "true_df = pred_1.merge(pred_2, on=\"PRODUCTREFERENCE\", how=\"inner\").merge(pred_3, on=\"PRODUCTREFERENCE\", how=\"inner\")\n",
    "true_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCTREFERENCE</th>\n",
       "      <th>Prediction_Period_1</th>\n",
       "      <th>Prediction_Period_2</th>\n",
       "      <th>Prediction_Period_3</th>\n",
       "      <th>exret_x</th>\n",
       "      <th>exret_y</th>\n",
       "      <th>exret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>0.019233</td>\n",
       "      <td>0.065684</td>\n",
       "      <td>0.048871</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>-0.064300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.072171</td>\n",
       "      <td>0.048816</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.002610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441</td>\n",
       "      <td>0.021537</td>\n",
       "      <td>0.064752</td>\n",
       "      <td>0.049314</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>-0.004000</td>\n",
       "      <td>-0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>727</td>\n",
       "      <td>0.009812</td>\n",
       "      <td>0.071117</td>\n",
       "      <td>0.048629</td>\n",
       "      <td>-0.014238</td>\n",
       "      <td>-0.005774</td>\n",
       "      <td>0.005192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>814</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.064102</td>\n",
       "      <td>0.050063</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>-0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>105997</td>\n",
       "      <td>0.014962</td>\n",
       "      <td>0.067656</td>\n",
       "      <td>0.049218</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>-0.014700</td>\n",
       "      <td>-0.017900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>106455</td>\n",
       "      <td>0.010205</td>\n",
       "      <td>0.065948</td>\n",
       "      <td>0.048407</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>-0.014100</td>\n",
       "      <td>-0.019300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>106484</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.066112</td>\n",
       "      <td>0.046670</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>-0.062100</td>\n",
       "      <td>0.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>106485</td>\n",
       "      <td>-0.000731</td>\n",
       "      <td>0.065273</td>\n",
       "      <td>0.046860</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>-0.059300</td>\n",
       "      <td>-0.062400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>106517</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.068675</td>\n",
       "      <td>0.049594</td>\n",
       "      <td>0.030605</td>\n",
       "      <td>0.032693</td>\n",
       "      <td>0.008251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>269 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PRODUCTREFERENCE  Prediction_Period_1  Prediction_Period_2  \\\n",
       "0                  29             0.019233             0.065684   \n",
       "1                  35             0.001127             0.072171   \n",
       "2                 441             0.021537             0.064752   \n",
       "3                 727             0.009812             0.071117   \n",
       "4                 814             0.020906             0.064102   \n",
       "..                ...                  ...                  ...   \n",
       "264            105997             0.014962             0.067656   \n",
       "265            106455             0.010205             0.065948   \n",
       "266            106484             0.000270             0.066112   \n",
       "267            106485            -0.000731             0.065273   \n",
       "268            106517             0.008111             0.068675   \n",
       "\n",
       "     Prediction_Period_3   exret_x   exret_y     exret  \n",
       "0               0.048871  0.046100  0.002400 -0.064300  \n",
       "1               0.048816  0.002600  0.010800  0.002610  \n",
       "2               0.049314  0.000800 -0.004000 -0.014400  \n",
       "3               0.048629 -0.014238 -0.005774  0.005192  \n",
       "4               0.050063  0.054600  0.018400 -0.000400  \n",
       "..                   ...       ...       ...       ...  \n",
       "264             0.049218  0.009600 -0.014700 -0.017900  \n",
       "265             0.048407  0.003100 -0.014100 -0.019300  \n",
       "266             0.046670  0.059200 -0.062100  0.053100  \n",
       "267             0.046860  0.059200 -0.059300 -0.062400  \n",
       "268             0.049594  0.030605  0.032693  0.008251  \n",
       "\n",
       "[269 rows x 7 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = predictions_df.dropna().merge(true_df, on=\"PRODUCTREFERENCE\", how=\"inner\")\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = combined_df.iloc[:, 1:3].to_numpy().flatten()\n",
    "trues = combined_df.iloc[:, 4:6].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import R2Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.7813)\n"
     ]
    }
   ],
   "source": [
    "metrics = R2Score()\n",
    "# input = torch.tensor(preds[:,:,0].flatten())\n",
    "# target = torch.tensor(trues[:,:,0].flatten())\n",
    "\n",
    "input = torch.tensor(preds)\n",
    "target = torch.tensor(trues)\n",
    "\n",
    "metrics.update(input, target)\n",
    "print(metrics.compute())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
